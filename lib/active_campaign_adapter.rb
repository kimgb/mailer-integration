# ActiveCampaignAdapter

# net/http to communicate with ActiveCampaign API. net/https for SSL on that connection.
require 'net/http'
require 'net/https'

# JSON to consume the API.
require 'json'

# Active Support's Hash extensions give us Hash#except and HashWithIndifferentAccess
require 'active_support/core_ext/hash'

# Some requires that are redundant for development in Ruby 2+, but may be needed in production where Ruby is 1.9.3.
require 'logger'
require 'pathname'

require_relative '../config/config'
require_relative 'sql'
require_relative 'models'
require_relative 'assist_adapter'

module ActiveCampaignAdapter
  # AssistAdapter provides the client method for direct db access
  # Also aliased as assist_client
  include AssistAdapter

  def root_dir
    @dir ||= Pathname.new(File.join("/", "opt", "email_integration"))
  end

  def log_dir
    File.join(root_dir, "log")
  end

  def self.sync_from_mailer
    @logger = Logger.new(File.join(log_dir, "from_mailer.log"), "monthly")
    @logger.debug "*** BEGINNING SYNC FROM MAILER ***"

    @this_run = DateTime.now
    filter = (last_run("down") << 1).strftime("%F") # previous month

    begin
      sync_campaigns(filter: filter)

      @logger.debug "Finished, saving this run as complete"
      save_run("down")
    rescue Exception => err
      @logger.error "#{err.class}: #{err.message}"
      @logger.error err.backtrace
    ensure
      @logger.close
    end
  end

  # Get campaigns, starting with the oldest. For each campaign, call
  # sync_campaign.
  def sync_campaigns(args={})
    page = args[:page] ||= 1

    @logger.debug "*** REQUESTING PAGE #{page}, FILTER: #{args[:filter] || 'None'}"
    response = parse_request(list_campaigns(page, args[:filter]))

    unless response["result_code"].zero? # 10 per page on campaigns
      response.slice(*(0..9).map(&:to_s)).values.each do |campaign|
        sync_campaign(campaign)
      end

      sync_campaigns(page: page + 1, filter: args[:filter])
    end
  end

  # Get the message(s), in plaintext. [Multiple messages in case of split test
  # campaigns.] Store the first as a Rec.
  # - Get the recipients, in reverse order of priority: Unopened -> Opened ->
  #   Clicked -> Forwarded. Unsubscribe overrides all and cannot be overridden.
  #   Bounce overrides all but unsub, but is always overridden.
  # WARNING: Getting the recipient lists can be a hefty request! I've tested up
  # to ~8_300 records retrieved (>100_000 lines returned) without breaking.
  def sync_campaign(campaign)
    @logger.debug "*** STARTING SYNC FOR CAMPAIGN #{campaign["name"].upcase}"
    # Messages can be found at campaign["messages"]; an array
    # I'm not aware of any cases of messages arrays of size > 1, but should
    # be prepared to handle it just in case.
    # More than one message may occur in the case of a split test campaign.
    # Since reports are generated by reference to the campaign, creating
    # more than one Rec per campaign will cause headaches.
    messages = campaign["messages"]

    if (message = messages.first)
      # store message as a rec. TypeID 14 is 'email'. Classification1 486 is
      # 'communications'. 606 is 'Mass Email'. Note oldrecid is a column that
      # *was* null for all but ~800 rows in the table; I've repurposed it here
      # to store the Active Campaign id as a kind of foreign key, but it could
      # turn out to be a fragile piece.
      rec = Rec.find(oldrecid: campaign["id"]) ||
        Rec.new(notes: message["text"].gsub(/(?<!\r)\n/, "\r\n"),
                creationdate: message["cdate"], oldrecid: campaign["id"],
                lastmodificationdate: message["mdate"], typeid: 14,
                classification1: 486, classification2: 606,
                name: message["subject"])

      if rec.save
        # get campaign reports:
        # opens - paginated! need a recursive method
        sync_campaign_opens(campaign["id"], rec)

        # clicks and forwards - need messageid in addition to campaignid - so
        # will need to iterate messages.
        sync_campaign_clicks_and_forwards(campaign["id"], messages, rec)

        # Bounces and unsubscribes - most straightforward of the lot
        sync_campaign_bounces(campaign["id"], rec)
        sync_campaign_unsubscribes(campaign["id"], rec)
      end
    else
      @logger.debug "No message found for campaign, skipping"
    end
  end

  # Snowballs a list of emails to be batch updated all at once, using recursion.
  # Once it runs out of pages, updates all such emails with the "opened" status.
  def sync_campaign_opens(id, rec, emails=[], page=1)
    response = parse_request(list_opens(id, page))

    if response["result_code"].zero?
      emails.each_slice(SUBSET) { |s| sync_contacts(s, "opened", rec) }
      # sync_contacts(emails, "opened", rec)
    else
      @logger.debug "Getting campaign opens, page #{page}"
      new_emails = response.except(*metadata).values.map { |c| c["email"] }
      sync_campaign_opens(id, rec, emails + new_emails, page + 1)
    end
  end

  def sync_campaign_clicks_and_forwards(id, messages, rec)
    @logger.debug "Getting campaign clicks and forwards"
    messages.each do |msg|
      clicks = parse_request(list_clicks(id, msg["id"]))
      # forwards = parse_request(list_forwards(id, msg["id"]))
      sync_campaign_clicks(clicks, rec) unless clicks["result_code"].zero?
      # sync_campaign_forwards(forwards, rec) unless forwards["result_code"].zero?
    end
  end

  def sync_campaign_clicks(clicks, rec)
    links = clicks.except(*metadata).values.map { |link| link["info"] }.flatten
    emails = links.map { |click| click["email"] }

    emails.each_slice(SUBSET) { |s| sync_contacts(s, "clicked", rec) }
    # sync_contacts(emails, "clicked", rec)
  end

  # can't build this one out until I find somewhere it's happened
  def _sync_campaign_forwards(forwards, rec)
  end

  def sync_campaign_bounces(id, rec)
    @logger.debug "Getting campaign bounces"
    response = parse_request(list_bounces(id))

    unless response["result_code"].zero?
      emails = response.except(*metadata).values.map { |c| c["email"] }
      emails.each_slice(SUBSET) { |s| sync_contacts(s, "bouncing", rec) }
      # sync_contacts(emails, "bouncing", rec)
    end
  end

  def sync_campaign_unsubscribes(id, rec)
    @logger.debug "Getting campaign unsubscribes"
    response = parse_request(list_unsubscribes(id))

    unless response["result_code"].zero?
      emails = response.except(*metadata).values.map { |c| c["email"] }
      emails.each_slice(SUBSET) { |s| sync_contacts(s, "unsubscribed", rec) }
      # sync_contacts(emails, "unsubscribed", rec)
    end
  end

  def metadata
    @metadata ||= ["result_code", "result_message", "result_output"]
  end

  def timer
    elapsed = Time.now - @timestamp
    @timestamp = Time.now

    elapsed
  end

  # Watch count vs. size. Can't call size on Sequel datasets. (Alias it?)
  # has grown a little out of hand. but it remains fairly DRY.
  def sync_contacts(emails, health, rec)
    @logger.debug "Performing batch sync with #{emails.size} emails, starting at " +
      "#{@timestamp = Time.now}"

    contacts = Contact.where(email: emails)
    junction = ContactRec.where(rec: rec)
    @logger.debug "Queries composed in #{timer}"

    # Update contactrecs, for those with prior joins, and contacts,
    # unless they're unsubscribed, with the latest health.
    contact_updates = contacts.exclude(emailhealth: ["unsubscribed", health])
      .update(emailhealth: health)
    @logger.debug "Updated emailhealth on #{contact_updates} Contacts in #{timer}"

    # Update deliverystatus on the ContactRecs by inner joining to Contacts
    cr_updates = junction.join(contacts, contactid: :contactid)
      .exclude(deliverystatus: health).update(deliverystatus: health)
    @logger.debug "Updated deliverystatus on #{cr_updates} ContactRecs in #{timer}"

    # Create joins thru the ContactRec table, where there are none yet.
    inserts = contacts.left_join(junction, contactid: :contactid)
      .where(t1__recid: nil).select(:contact__contactid).distinct
      .map { |c| [c.contactid, rec.recid, 50, 1, 1, health] }
    @logger.debug "Composed insert in #{timer}, now executing"

    # And insert them in a batch
    ContactRec.import(
      [:ContactID, :RecID, :TypeID, :CreatorID, :LastModifierID,
       :DeliveryStatus], inserts)
    @logger.debug "Inserted #{inserts.size} new rows to the ContactRec table in #{timer}"
  end

  # - Locate a Contact with matching Email (or ID, if that's stored on mailer).
  # - Update the EmailHealth field, based on precedence
  # - Associate the Contact to the Rec
  def sync_contact(email, health, rec)
    if (c = Contact.find(email: email))
      puts "Found contact with email #{email}, syncing"
      c.emailhealth != "unsubscribed" && (c.emailhealth = health) && c.save
      # Build association, unless it's already present
      unless c.recs.include?(rec)
        (cr = ContactRec.new(contactid: c.contactid, recid: rec.recid,
          typeid: 50, creatorid: 1, lastmodifierid: 1)) && cr.save
      end
    end
  end

  def self.sync_to_mailer
    @this_run = DateTime.now
    @logger = Logger.new(File.join(log_dir, "to_mailer.log"), "monthly")
    @logger.debug "\n*** BEGINNING SYNC TO MAILER ***\n"

    # Rudimentary logging
    @logger.debug "Fetching contacts from Assist"
    @contacts = contacts_with_email.all
    # @contacts = contacts_with_email.all

    @logger.debug "Preparing to push #{@contacts.size} contacts to mailer"

    #mutex = Mutex.new # @logger.rb is already mutexed
    threads = []
    begin
      # Four threads runs at concurrency limit most of the time, but leaves gaps
      (0..3).map { |i| threads << sync_thread(i) } #, mutex) }
      threads.map(&:join)

      @logger.debug "Finished, saving this run as complete"
      save_run("up")
    rescue Exception => err
      @logger.error "#{err.class}: #{err.message}"
      @logger.error err.backtrace
    ensure
      @logger.close
    end
  end


  private

  # Fetches the last run time from disk
  def last_run(direction)
    f = File.join(self.log_dir, "last_#{direction}_run.txt")
    if File.exists?(f)
      # Reads first line of the file into DateTime format
      @last_run ||= DateTime.parse(File.open(f, &:readline).strip)
    else
      @last_run ||= DateTime.parse('1970-01-01')
    end
  end

  # Saves this run time to disk
  def save_run(direction)
    f = File.join(self.log_dir, "last_#{direction}_run.txt")
    File.open(f, "w") { |f| f.puts @this_run.strftime("%FT%T") }
  end

  def root(i = nil)
    if i
      instance_variable_get("@root#{i}") || set_root("@root#{i}")
    else
      @root || set_root("@root")
    end
  end

  def set_root(var)
    http = instance_variable_set(var, Net::HTTP.new("mailer.nuw.org.au", 443))
    http.use_ssl = true
    http.verify_mode = OpenSSL::SSL::VERIFY_NONE

    http
  end

  def parse_request(request_object)
    JSON.parse(root.request(request_object).body)
  end

  def _trim_page(response, length)
    response.slice(*(0..length).map(&:to_s)).values
  end

  # Spawns a subscriber sync thread
  def sync_thread(i) #, mutex)
    Thread.new do
      (i..@contacts.size - 1).step(4) do |n|
        http = root(i)
        contact = @contacts[n]
        update_contact(http, contact)
      end
    end
  end

  def update_contact(http, contact)
    reqres = http.request(parameterise(contact))
    response = JSON.parse(reqres.body)

    response
  end

  # Be aware - ActiveCampaign fields that are custom (that's most of them!)
  # need to be created before use, either through the API or in the UI.
  # Each new custom field means another magic number for MAILER_FIELDS.
  def parameterise(contact)
    post = sync_subscriber
    # Note, must be submitted as form data. Not JSON in the body. (I tried)
    post.set_form_data(
      "p[#{LIST_ID}]" => LIST_ID,
      "email" => contact[:email],
      "first_name" => contact[:firstname],
      "last_name" => contact[:lastname],
      "field[#{MAILER_FIELDS[:id]},0]" => contact[:id],
      "field[#{MAILER_FIELDS[:state]},0]" => contact[:resstate],
      "field[#{MAILER_FIELDS[:tags]},0]" => contact[:tags],
      "field[#{MAILER_FIELDS[:unionstatus]},0]" => contact[:unionstatus],
      "field[#{MAILER_FIELDS[:delegate]},0]" => contact[:delegate],
      "field[#{MAILER_FIELDS[:hsr]},0]" => contact[:hsr],
      "field[#{MAILER_FIELDS[:memberstatus]},0]" => contact[:memberstatus],
      "field[#{MAILER_FIELDS[:industry]},0]" => contact[:industry],
      "field[#{MAILER_FIELDS[:workplace]},0]" => contact[:workplace],
      "field[#{MAILER_FIELDS[:workplaceid]},0]" => contact[:workplaceid],
      "field[#{MAILER_FIELDS[:workplacestate]},0]" => contact[:workplacestate],
      "field[#{MAILER_FIELDS[:branch]},0]" => contact[:branchid]
    )

    post
  end

  def queryise(hash)
    # equalise = lambda { |ary| ary.join("=") }
    rollup_and_flatten_hash(hash)
      .each_slice(2).map{ |a| URI.encode(a.join("=")) }.join("&")
      # .map(&:join_equal)
      # .map(&URI.method(:encode))
      # .join_ampers
  end

  # flattens a hash into an array while rolling up nested keys (recursive)
  # { filters: { since: "2015-06-21" } } => ["filters[since]", "2015-06-21"]
  def rollup_and_flatten_hash(hash, key="")
    hash.flat_map do |k, v|
      new_key = key + (key.empty? ? "#{k}" : "[#{k}]")
      if v.is_a?(Hash)
        rollup_and_flatten_hash(v, new_key)
      else
        [new_key, v]
      end
    end
  end

  ## Methods below are for instantiating request objects to the mailer API.

  def sync_subscriber
    query_params = queryise(api_key: API_KEY, api_action: "subscriber_sync",
      api_output: "json")
    Net::HTTP::Post.new("/admin/api.php?#{query_params}")
  end

  def list_campaigns(page, since=nil)
    params = { api_key: API_KEY, api_action: "campaign_list",
               api_output: "json", sort: "cdate", sort_direction: "ASC",
               page: page }
    if since
      params[:filters] = { ldate_since_datetime: since }
    else
      params[:ids] = "all"
    end
    # gunning for impenetrability with this version:
    #params.[]=(*since ? [:filters,{ldate_since_datetime: since}] : [:ids,"all"])

    query_params = queryise(params)
    Net::HTTP::Get.new("/admin/api.php?#{query_params}")
  end

  ## So. These campaign report lists are super inconsistent. Some paginated
  ## (and sorted), some not. Some need message_id as well as campaign_id, some
  ## don't. Can't even get unopens working - from the API explorer, let alone
  ## in my own program! And they all return different data, arranged in
  ## different ways. Abstraction is difficult under the circumstances.

  # can't get this one working.
  def _list_unopens(campaign_id, message_id)
    query_params = queryise(api_key: API_KEY, api_output: "json",
      api_action: "campaign_report_unopen_list", campaignid: campaign_id,
      messageid: message_id)
    Net::HTTP::Get.new("/admin/api.php?#{query_params}")
  end

  # This is the only one with pagination and sorting
  def list_opens(campaign_id, page)
    query_params = queryise(api_key: API_KEY, api_output: "json",
      api_action: "campaign_report_open_list", campaignid: campaign_id,
      sort: "tstamp", sort_direction: "ASC", page: page)
    Net::HTTP::Get.new("/admin/api.php?#{query_params}")
  end

  # This one has the emails grouped by the link they clicked. Same email can
  # be repeated across different links.
  def list_clicks(campaign_id, message_id)
    query_params = queryise(api_key: API_KEY, api_output: "json",
      api_action: "campaign_report_link_list", campaignid: campaign_id,
      messageid: message_id)
    Net::HTTP::Get.new("/admin/api.php?#{query_params}")
  end

  # Although this one hasn't returning anything yet, I'm inclined to think it's
  # working. Forwarding is just very rare. Keep testing on bigger campaigns.
  def list_forwards(campaign_id, message_id)
    query_params = queryise(api_key: API_KEY, api_output: "json",
      api_action: "campaign_report_forward_list", campaignid: campaign_id,
      messageid: message_id)
    Net::HTTP::Get.new("/admin/api.php?#{query_params}")
  end

  # standard, keyed on incrementing id with some extra bounce info
  def list_bounces(campaign_id)
    query_params = queryise(api_key: API_KEY, api_output: "json",
      api_action: "campaign_report_bounce_list", campaignid: campaign_id)
    Net::HTTP::Get.new("/admin/api.php?#{query_params}")
  end

  # standard, keyed on incrementing id with some unsub info
  def list_unsubscribes(campaign_id)
    query_params = queryise(api_key: API_KEY, api_output: "json",
      api_action: "campaign_report_unsubscription_list",
      campaignid: campaign_id)
    Net::HTTP::Get.new("/admin/api.php?#{query_params}")
  end
end
